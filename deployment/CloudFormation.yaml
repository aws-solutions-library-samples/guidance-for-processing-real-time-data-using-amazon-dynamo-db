AWSTemplateFormatVersion: '2010-09-09'
Description: This template creates the required DynamoDB resources (SO9440) and deploys the aggregate Lambda function that performs the aggregation.

Resources:
  MyLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: blogrole
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaDynamoDBExecutionRole
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

  OrdersTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: Order_by_item
      AttributeDefinitions:
        - AttributeName: orderid
          AttributeType: S
        - AttributeName: order_date
          AttributeType: S
      KeySchema:
        - AttributeName: orderid
          KeyType: HASH
        - AttributeName: order_date
          KeyType: RANGE
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5
      Tags:
        - Key: Name
          Value: Order_by_item
      StreamSpecification:
        StreamViewType: NEW_AND_OLD_IMAGES

  OrdersByDateTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: item_count_by_date
      AttributeDefinitions:
        - AttributeName: item_number
          AttributeType: S
        - AttributeName: order_date
          AttributeType: S
      KeySchema:
        - AttributeName: item_number
          KeyType: HASH
        - AttributeName: order_date
          KeyType: RANGE
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5
      Tags:
        - Key: Name
          Value: item_count_by_date

  OrdersHashTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: orders_hash
      AttributeDefinitions:
        - AttributeName: hash_key
          AttributeType: S
      KeySchema:
        - AttributeName: hash_key
          KeyType: HASH
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5
      Tags:
        - Key: Name
          Value: orders_hash

  OrdersTablePolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: OrdersTablePolicy
      Roles:
        - !Ref MyLambdaRole
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - dynamodb:GetItem
              - dynamodb:PutItem
              - dynamodb:UpdateItem
              - dynamodb:DeleteItem
            Resource:
              - !GetAtt OrdersTable.Arn

  OrdersByDateTablePolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: OrdersByDateTablePolicy
      Roles:
        - !Ref MyLambdaRole
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - dynamodb:GetItem
              - dynamodb:PutItem
              - dynamodb:UpdateItem
              - dynamodb:DeleteItem
            Resource:
              - !GetAtt OrdersByDateTable.Arn
              - !GetAtt OrdersHashTable.Arn
  
  ProcessEventLambda:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.10
      Timeout: 300
      Handler: index.lambda_handler
      Role: !GetAtt MyLambdaRole.Arn 
      Code:
        ZipFile: |
            import json
            import os
            import boto3
            import hashlib

            dynamodb = boto3.resource("dynamodb")
            aggregate_table = dynamodb.Table(os.environ["target_count_table"])  # Aggregate table
            hash_store_table = dynamodb.Table(os.environ["hash_store_table"])  # Hash store table

            def generate_item_hash(order_date, orderid, item_number):
                # Generate a SHA-256 hash based on the key attributes
                hash_input = f"{order_date}:{orderid}:{item_number}"
                return hashlib.sha256(hash_input.encode('utf-8')).hexdigest()

            def lambda_handler(event, context):
                for record in event["Records"]:
                    new_item = record["dynamodb"]["NewImage"]

                    # Extract the order date, order ID, and item number from the new item
                    order_date = new_item.get("order_date", {}).get("S")
                    orderid = new_item.get("orderid", {}).get("S")
                    item_number = new_item.get("item_number", {}).get("S")
                    quantity = int(new_item.get("quantity", {}).get("N", 0))

                    # Ensure that the required attributes exist
                    if order_date and orderid and item_number and quantity:
                        # Generate a hash based on order_date, orderid, and item_number
                        item_hash = generate_item_hash(order_date, orderid, item_number)
                        # Construct the partition key for the item_count_by_date table
                        date_partition_key = order_date.split("T")[0]

                    # Check if the hash exists in the orders_hash table
                    try:
                        response = hash_store_table.get_item(Key={"hash_key": item_hash})
                        if "Item" in response:
                            print(f"Item with hash {item_hash} has already been processed. Skipping.")
                            continue  # Skip processing since it's already been handled
                    except Exception as e:
                        print(f"Error checking orders_hash table: {e}")
                        continue  # If there's an issue with checking, skip this item

                    # Proceed with updating the item_count_by_date table
                    try:
                        aggregate_table.update_item(
                            Key={"order_date": date_partition_key, "item_number": item_number},
                            UpdateExpression="ADD quantity :val",
                            ExpressionAttributeValues={":val": quantity}
                        )
                        
                        # Store the hash in the orders_hash table to mark it as processed
                        hash_store_table.put_item(Item={"hash_key": item_hash})

                    except Exception as e:
                        print(f"Error updating item_count_by_date table: {e}")
      Environment:
        Variables:
          target_count_table: !Ref OrdersByDateTable
          hash_store_table: !Ref OrdersHashTable

  LambdaEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      EventSourceArn: !GetAtt OrdersTable.StreamArn
      FunctionName: !Ref ProcessEventLambda
      StartingPosition: TRIM_HORIZON
      FilterCriteria:
        Filters:
          - Pattern: "{\"eventName\": [\"INSERT\", \"MODIFY\"]}"
